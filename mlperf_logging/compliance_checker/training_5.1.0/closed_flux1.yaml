# Stable diffusion uses two metrics, FID and CLIP.
# These metrics can be calculated offline, using different scripts
# and logged seperatly. Therefore, we create a virtual key
# called aggregated_eval_accuracy, which aggregates
# both metrics into a single log line

- KEY:
    NAME:  global_batch_size
    REQ:   AT_LEAST_ONE
    CHECK: " v['value'] >= 0 "

- KEY:
    NAME:  evaluation_frequency
    REQ:   EXACTLY_ONE
    CHECK: " v['value'] == 262144"

- KEY:
    NAME:  opt_name
    REQ:   EXACTLY_ONE
    CHECK: " v['value'] == 'adamw' "

- KEY:
    NAME:  opt_adamw_beta_1
    REQ:   EXACTLY_ONE
    CHECK: " v['value'] == 0.9 "

- KEY:
    NAME:  opt_adamw_beta_2
    REQ:   EXACTLY_ONE
    CHECK: " v['value'] == 0.95 "

- KEY:
    NAME:  opt_adamw_epsilon
    REQ:   EXACTLY_ONE
    CHECK: " v['value'] == 1e-08 "

- KEY:
    NAME:  opt_adamw_weight_decay
    REQ:   EXACTLY_ONE
    CHECK: " v['value'] == 0.1 "

- KEY:
    NAME:  opt_base_learning_rate
    REQ:   EXACTLY_ONE
    CHECK: " v['value'] >= 0.0 "

- KEY:
    NAME:  opt_learning_rate_warmup_steps
    REQ:   EXACTLY_ONE
    CHECK: " v['value'] >= 0 "

- KEY:
    NAME:  opt_gradient_clip_norm
    REQ:   EXACTLY_ONE
    CHECK: " v['value'] == 1.0 "

- KEY:
    NAME: eval_accuracy
    REQ: AT_LEAST_ONE
    CHECK:
        - "'samples_count' in v['metadata']"
    ATLEAST_ONE_CHECK: "v['value'] <= 0.586 and v['value'] > 0.0"
